# create_my_faiss_rag.py
import json
import os
import numpy as np
import faiss
from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel

# -------------------------------
# 1. é…ç½®å‚æ•°
# -------------------------------
MODEL_NAME = "./clip_model_cache"  # CLIP æ¨¡å‹ï¼Œè¾“å‡º 512 ç»´å‘é‡
DIMENSION = 512  # å‘é‡ç»´åº¦

# Faiss ç´¢å¼•ä¿å­˜è·¯å¾„
INDEX_DIR = "./multimodal_rag_system_output/data_storage/vector_indices"
os.makedirs(INDEX_DIR, exist_ok=True)

TEXT_INDEX_PATH = os.path.join(INDEX_DIR, "my_phone_IP_text_vector_index.faiss")
IMAGE_INDEX_PATH = os.path.join(INDEX_DIR, "my_phone_IP_image_vector_index.faiss")
MEAN_INDEX_PATH = os.path.join(INDEX_DIR, "my_phone_IP_mean_vector_index.faiss")

# ç¤ºä¾‹æ•°æ®ï¼šæ–‡æœ¬-å›¾ç‰‡å¯¹åˆ—è¡¨
# è¯·ç¡®ä¿å›¾ç‰‡è·¯å¾„å­˜åœ¨ï¼å¯ä»¥æ›¿æ¢æˆä½ è‡ªå·±çš„æ•°æ®
RAG_DATA_FILE = "./RAG_data/mobilePhone.json"  # å¯æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„
# ä»æ–‡ä»¶è¯»å–å›¾æ–‡å¯¹
data_pairs = []
with open(RAG_DATA_FILE, 'r', encoding='utf-8') as f:
    data_pairs = json.load(f)

# -------------------------------
# 2. åŠ è½½ CLIP æ¨¡å‹å’Œå¤„ç†å™¨
# -------------------------------
print("Loading CLIP model...")
model = CLIPModel.from_pretrained(MODEL_NAME)
processor = CLIPProcessor.from_pretrained(MODEL_NAME)

# ä½¿ç”¨ CPUï¼Œå¦‚æœ‰ GPU å¯å¯ç”¨
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# -------------------------------
# 3. åˆ›å»º Faiss ç´¢å¼•ï¼ˆFlat L2 ç›¸ä¼¼åº¦ï¼‰
# -------------------------------
print("Creating Faiss indexes...")

def load_or_create_index(path, dimension):
    if os.path.exists(path):
        print(f"ğŸ“‚ åŠ è½½å·²æœ‰ç´¢å¼•: {path}")
        index = faiss.read_index(path)
        print(f"âœ… å½“å‰å‘é‡æ•°: {index.ntotal}, ç»´åº¦: {index.d}")
    else:
        print(f"ğŸ†• åˆ›å»ºæ–°ç´¢å¼•: {path}")
        index = faiss.IndexFlatIP(dimension)  # ä½¿ç”¨ IP è·ç¦»
    return index

text_index = load_or_create_index(TEXT_INDEX_PATH, DIMENSION)
image_index = load_or_create_index(IMAGE_INDEX_PATH, DIMENSION)
mean_index = load_or_create_index(MEAN_INDEX_PATH, DIMENSION)

print(f"Text index (ntotal): {text_index.ntotal}")
print(f"Image index (ntotal): {image_index.ntotal}")
print(f"Mean index (ntotal): {mean_index.ntotal}")

# -------------------------------
# 4. å¤„ç†æ¯ä¸€å¯¹æ–‡æœ¬-å›¾ç‰‡ï¼Œç”Ÿæˆå‘é‡å¹¶æ·»åŠ åˆ°ç´¢å¼•
# -------------------------------
ids = []  # å­˜å‚¨ IDï¼ˆå¯æ‰©å±•ä¸ºå…ƒæ•°æ®ï¼‰
for i, pair in enumerate(data_pairs):
    text = pair["text"]
    img_path = pair["image_path"]

    print(f"\nProcessing pair {i+1}: {text}")

    # --- æ–‡æœ¬å‘é‡åŒ– ---
    inputs_text = processor(text=text, return_tensors="pt", padding=True, truncation=True).to(device)
    with torch.no_grad():
        text_features = model.get_text_features(**inputs_text)
    text_vec = text_features.cpu().numpy().astype('float32')
    text_vec = text_vec / np.linalg.norm(text_vec, axis=1, keepdims=True)

    # --- å›¾åƒå‘é‡åŒ– ---
    if not os.path.exists(img_path):
        print(f"âš ï¸  Image not found: {img_path}, skipping...")
        continue

    image = Image.open(img_path).convert("RGB")
    inputs_image = processor(images=image, return_tensors="pt").to(device)
    with torch.no_grad():
        image_features = model.get_image_features(**inputs_image)
    image_vec = image_features.cpu().numpy().astype('float32')
    image_vec = image_vec / np.linalg.norm(image_vec, axis=1, keepdims=True)

    # --- å½’ä¸€åŒ–ï¼ˆCLIP å‘é‡é€šå¸¸å·²å½’ä¸€åŒ–ï¼Œä½† Faiss ä¸­å¸¸ä½¿ç”¨å†…ç§¯æœç´¢ï¼Œè¿™é‡Œä¿æŒ L2ï¼‰---
    # æ³¨æ„ï¼šCLIP è¾“å‡ºçš„æ˜¯å½’ä¸€åŒ–å‘é‡ï¼Œæ‰€ä»¥ L2 è·ç¦» â‰ˆ 2 - 2*cosineï¼Œé€‚åˆè¯­ä¹‰ç›¸ä¼¼åº¦

    # --- æ·»åŠ åˆ°ç´¢å¼• ---
    text_index.add(text_vec)
    image_index.add(image_vec)

    # --- è®¡ç®—å¹³å‡å‘é‡ ---
    mean_vec = (text_vec + image_vec) / 2
    mean_vec = mean_vec / np.linalg.norm(mean_vec, axis=1, keepdims=True)
    mean_index.add(mean_vec)

    ids.append(i)
    print(f"âœ… Added vector {i} to all indexes.")

# -------------------------------
# 5. ä¿å­˜ç´¢å¼•åˆ°æ–‡ä»¶
# -------------------------------
print("\nSaving indexes to disk...")
faiss.write_index(text_index, TEXT_INDEX_PATH)
faiss.write_index(image_index, IMAGE_INDEX_PATH)
faiss.write_index(mean_index, MEAN_INDEX_PATH)

print(f"âœ… Text index saved to: {TEXT_INDEX_PATH}")
print(f"âœ… Image index saved to: {IMAGE_INDEX_PATH}")
print(f"âœ… Mean index saved to: {MEAN_INDEX_PATH}")

# -------------------------------
# 6. éªŒè¯ï¼šè¯»å–å¹¶æ£€æŸ¥æ•°é‡
# -------------------------------
print("\nValidating saved indexes:")
loaded_text_index = faiss.read_index(TEXT_INDEX_PATH)
loaded_image_index = faiss.read_index(IMAGE_INDEX_PATH)
loaded_mean_index = faiss.read_index(MEAN_INDEX_PATH)

print(f"Loaded text index - Total vectors: {loaded_text_index.ntotal}")
print(f"Loaded image index - Total vectors: {loaded_image_index.ntotal}")
print(f"Loaded mean index - Total vectors: {loaded_mean_index.ntotal}")

print("\nâœ… All done! You now have a local multi-modal RAG with 3 Faiss indexes.")